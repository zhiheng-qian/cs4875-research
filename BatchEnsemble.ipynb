{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"BatchEnsemble.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyM1FWTDdFjBw8xAOTwXJmXF"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"1fJXab4ybGGq"},"source":["<h1>BatchEnsemble: An Alternative Approach To Efficient Ensemble and Lifelong Learning<h1/>\n","\n","Yeming Wen, Dustin Tran & Jimmy Ba"]},{"cell_type":"markdown","metadata":{"id":"APXrAy0lba_B"},"source":["<h2>Classification with Wide ResNet and CIFAR10<h2/>"]},{"cell_type":"code","metadata":{"id":"cF4t-QLebjab","executionInfo":{"status":"ok","timestamp":1610011745556,"user_tz":-120,"elapsed":4262,"user":{"displayName":"Zhiheng Qian","photoUrl":"","userId":"13654940909956400032"}}},"source":["import os\n","import time\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","m = nn.Softplus()"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"P1C0MsYQbjW_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610011765204,"user_tz":-120,"elapsed":23868,"user":{"displayName":"Zhiheng Qian","photoUrl":"","userId":"13654940909956400032"}},"outputId":"0ae746bd-58a1-4983-b266-d68f3fac68cb"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"OXWXi-TqbjUC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610011984048,"user_tz":-120,"elapsed":3450,"user":{"displayName":"Zhiheng Qian","photoUrl":"","userId":"13654940909956400032"}},"outputId":"6f5fbb4e-ac15-4ca9-9caf-144214afff72"},"source":["import torchvision\n","import torchvision.transforms as transforms\n","data_dir = '/content/drive/My Drive/AALTO/cs4875-research/data/'\n","transform = transforms.Compose([\n","    transforms.ToTensor(),  # Transform to tensor\n","    transforms.Normalize((0.5,), (0.5,))  # Min-max scaling to [-1, 1]\n","])\n","\n","trainset = torchvision.datasets.CIFAR10(root=data_dir, train=True, download=True, transform=transform)\n","testset = torchvision.datasets.CIFAR10(root=data_dir, train=False, download=True, transform=transform)\n","\n","classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n","\n","trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True)\n","testloader = torch.utils.data.DataLoader(testset, batch_size=5, shuffle=False)"],"execution_count":16,"outputs":[{"output_type":"stream","text":["Files already downloaded and verified\n","Files already downloaded and verified\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"WmrxhBVSIG_T","executionInfo":{"status":"ok","timestamp":1610012144601,"user_tz":-120,"elapsed":979,"user":{"displayName":"Zhiheng Qian","photoUrl":"","userId":"13654940909956400032"}}},"source":["class Cov2dEnsemble(nn.Module):\n","    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, num_models=4, first_layer=False):\n","      super(Cov2dEnsemble, self).__init__()\n","      self.in_channels = in_channels\n","      self.out_channels = out_channels\n","      self.num_models = num_models\n","      self.first_layer = first_layer\n","      self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding, bias=False)\n","      self.alpha = nn.Parameter(torch.Tensor(num_models, in_channels))\n","      self.gamma = nn.Parameter(torch.Tensor(num_models, out_channels))\n","      nn.init.normal_(self.alpha, mean=1., std=0.5)\n","      nn.init.normal_(self.gamma, mean=1., std=0.5)\n","\n","    def forward(self, x):\n","      if not self.training and self.first_layer:\n","        x = torch.cat([x for i in range(self.num_models)], dim=0)\n","      examples_per_model = int(x.size(0) / self.num_models)\n","      alpha = torch.cat([self.alpha for i in range(examples_per_model)], dim=1).view([-1, self.in_channels])\n","      alpha.unsqueeze_(-1).unsqueeze_(-1)\n","      gamma = torch.cat([self.gamma for i in range(examples_per_model)], dim=1).view([-1, self.out_channels])\n","      gamma.unsqueeze_(-1).unsqueeze_(-1)\n","      return self.conv1(x*alpha)*gamma\n","\n","class FCEnsemble(nn.Module):\n","    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, num_models=4):\n","      super(FCEnsemble, self).__init__()\n","      self.in_channels = in_channels\n","      self.out_channels = out_channels\n","      self.num_models = num_models\n","      self.fc = nn.Linear(in_channels, out_channels, bias=False)\n","      self.alpha = nn.Parameter(torch.Tensor(num_models, in_channels))\n","      self.gamma = nn.Parameter(torch.Tensor(num_models, out_channels))\n","      nn.init.normal_(self.alpha, mean=1., std=0.5)\n","      nn.init.normal_(self.gamma, mean=1., std=0.5)\n","\n","    def forward(self, x):\n","      examples_per_model = int(x.size(0) / self.num_models)\n","      alpha = torch.cat([self.alpha for i in range(examples_per_model)], dim=1).view([-1, self.in_channels])\n","      gamma = torch.cat([self.gamma for i in range(examples_per_model)], dim=1).view([-1, self.out_channels])\n","      return self.fc(x*alpha)*gamma\n"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"EBffc7VwbjPb","executionInfo":{"status":"ok","timestamp":1610012144873,"user_tz":-120,"elapsed":749,"user":{"displayName":"Zhiheng Qian","photoUrl":"","userId":"13654940909956400032"}}},"source":["class BlockBatchEnsemble(nn.Module):\n","    def __init__(self, in_channels, out_channels, dropout_rate, stride=1, num_models=4):\n","        super(BlockBatchEnsemble, self).__init__()\n","        self.bn1 = nn.BatchNorm2d(in_channels)\n","        self.conv1 = Cov2dEnsemble(in_channels, out_channels, 3, stride=1, padding=1, num_models=num_models)\n","        self.dropout = nn.Dropout(p=dropout_rate)\n","        self.bn2 = nn.BatchNorm2d(out_channels)\n","        self.conv2 = Cov2dEnsemble(out_channels, out_channels, 3, stride=stride, padding=1, num_models=num_models)\n","        self.num_models = num_models\n","        # self.convs = [self.conv1, self.conv2]\n","        self.skip = nn.Sequential()\n","        if stride != 1 or in_channels != out_channels:\n","            self.skip = nn.Sequential(\n","                # nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=True),\n","                Cov2dEnsemble(in_channels, out_channels, 1, stride=stride, padding=0, num_models=num_models),\n","            )\n","    # def update_indices(self, indices):\n","    #     for m_conv in self.convs:\n","    #         m_conv.update_indices(indices)\n","\n","    def forward(self, x):\n","        curr_bs = x.size(0)\n","        out = self.dropout(self.conv1(F.relu(self.bn1(x))))\n","        out = self.conv2(F.relu(self.bn2(out)))\n","        out += self.skip(x)\n","        return out\n","\n","class GroupBlockBatchEnsemble(nn.Module):\n","    def __init__(self, in_channels, out_channels, n_blocks, dropout_rate, stride=1, num_models=4):\n","        super(GroupBlockBatchEnsemble, self).__init__()\n","        strides = [stride] + [1]*(int(n_blocks) - 1)\n","        self.in_channels = in_channels\n","        group = []\n","\n","        for stride in strides:\n","            group.append(BlockBatchEnsemble(self.in_channels, out_channels, dropout_rate, stride))\n","            self.in_channels = out_channels\n","\n","        self.group = nn.Sequential(*group)\n","\n","    def forward(self, x):\n","        return self.group(x)\n","\n","class WideResNetBatchEnsemble(nn.Module):\n","    def __init__(self, depth, widen_factor, dropout_rate, num_classes=10, num_models=4):\n","        super(WideResNetBatchEnsemble, self).__init__()\n","        assert ((depth-4)%6 == 0), \"Depth should be 6n+4.\"\n","        n = (depth - 4)/6\n","        k = widen_factor\n","        nStages = [16, 16*k, 32*k, 64*k]\n","\n","        self.conv1 = Cov2dEnsemble(in_channels=3, out_channels=nStages[0], kernel_size=1, stride=1, padding=0, num_models=num_models, first_layer=True)\n","        self.group1 = GroupBlockBatchEnsemble(nStages[0], nStages[1], n, dropout_rate, stride=1, num_models=num_models)\n","        self.group2 = GroupBlockBatchEnsemble(nStages[1], nStages[2], n, dropout_rate, stride=2, num_models=num_models)\n","        self.group3 = GroupBlockBatchEnsemble(nStages[2], nStages[3], n, dropout_rate, stride=2, num_models=num_models)\n","        self.bn1 = nn.BatchNorm2d(nStages[3])\n","\n","        self.relu = nn.ReLU(inplace=True)\n","        self.fc = FCEnsemble(nStages[3], num_classes, num_models)\n","        self.nStage3 = nStages[3]\n","\n","        # Initialize weights\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d):\n","                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n","                m.weight.data.normal_(0, np.sqrt(2. / n))\n","            elif isinstance(m, nn.BatchNorm2d):\n","                m.weight.data.fill_(1)\n","                m.bias.data.zero_()\n","\n","    def forward(self, x):\n","        x = self.conv1(x)\n","        x = self.group1(x)\n","        x = self.group2(x)\n","        x = self.group3(x)\n","        x = self.relu(self.bn1(x))\n","        x = F.avg_pool2d(x, 8)\n","        x = x.view(-1, self.nStage3)\n","        return self.fc(x)\n"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"JAGSpwbybjMn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610015926465,"user_tz":-120,"elapsed":2795924,"user":{"displayName":"Zhiheng Qian","photoUrl":"","userId":"13654940909956400032"}},"outputId":"d8907867-3af3-4675-f195-6698ca3e726c"},"source":["device = torch.device('cuda:0')\n","loss_func = nn.CrossEntropyLoss()\n","m = nn.LogSoftmax(dim=1)\n","eps = 0.01*2 # input ranges from (-1, 1)\n","learning_rate = 0.01\n","\n","def compute_brier_score(p, y):\n","  brier_score = torch.mean((y-torch.argmax(p, 1).float())**2)\n","  return brier_score\n","\n","def ensembleInBatch(model, optimizer):\n","  running_loss = 0.0\n","  running_brier = 0.0\n","  for epoch in range(numEpochs):\n","    # model.train()\n","    brier_score = 0.0\n","    total = 0\n","    for x, y in trainloader:\n","        x, y = x.to(device), y.to(device)\n","        optimizer.zero_grad()\n","        output = model(x)\n","        batch_brier_score = compute_brier_score(output, y)\n","        brier_score += torch.sum(batch_brier_score, 0).cpu().numpy().item()\n","        loss = loss_func(output, y)\n","        loss.backward()\n","        optimizer.step()\n","        total += y.size(0)\n","    if epoch == (numEpochs-1):\n","      running_loss = loss.item()\n","    print('Loss at epoch {} is {}'.format(epoch, loss.item()))\n","    print('Brier score at epoch {} is {}'.format(epoch, brier_score/total))\n","  return running_loss, brier_score/total\n","\n","\n","numEpochs = 40\n","training_loss = []\n","training_brier = []\n","t0 = time.time()\n","# for i in range(4):\n","model = WideResNetBatchEnsemble(28, 4, 0.5)\n","model.to(device)\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","loss, brier = ensembleInBatch(model, optimizer)\n","  # training_loss.append(loss)\n","  # training_brier.append(brier)\n","print('NLL Loss is {}'.format(np.mean(loss)))\n","print('Brier score is {}'.format(np.mean(brier)))\n","print('Training time: {} seconds'.format(time.time() - t0))\n"],"execution_count":27,"outputs":[{"output_type":"stream","text":["Loss at epoch 0 is 1.9276663064956665\n","Brier score at epoch 0 is 0.1217960625076294\n","Loss at epoch 1 is 1.76310133934021\n","Brier score at epoch 1 is 0.1121630000114441\n","Loss at epoch 2 is 1.448449969291687\n","Brier score at epoch 2 is 0.0917960625076294\n","Loss at epoch 3 is 1.3844554424285889\n","Brier score at epoch 3 is 0.0789084375\n","Loss at epoch 4 is 1.2089399099349976\n","Brier score at epoch 4 is 0.0642072187614441\n","Loss at epoch 5 is 1.0314240455627441\n","Brier score at epoch 5 is 0.05087234375\n","Loss at epoch 6 is 0.6248108744621277\n","Brier score at epoch 6 is 0.04362690625190735\n","Loss at epoch 7 is 0.7734381556510925\n","Brier score at epoch 7 is 0.03828131249904632\n","Loss at epoch 8 is 0.6490518450737\n","Brier score at epoch 8 is 0.0342365625\n","Loss at epoch 9 is 0.5573354959487915\n","Brier score at epoch 9 is 0.030890593752861024\n","Loss at epoch 10 is 0.5704811215400696\n","Brier score at epoch 10 is 0.02788315625190735\n","Loss at epoch 11 is 0.7347951531410217\n","Brier score at epoch 11 is 0.02486296875\n","Loss at epoch 12 is 0.4050733149051666\n","Brier score at epoch 12 is 0.0231046875\n","Loss at epoch 13 is 0.38667070865631104\n","Brier score at epoch 13 is 0.02131643750190735\n","Loss at epoch 14 is 0.512344479560852\n","Brier score at epoch 14 is 0.019173375000953674\n","Loss at epoch 15 is 0.47257429361343384\n","Brier score at epoch 15 is 0.017684812500476838\n","Loss at epoch 16 is 0.34359169006347656\n","Brier score at epoch 16 is 0.016462437500953674\n","Loss at epoch 17 is 0.4562455117702484\n","Brier score at epoch 17 is 0.01555453125\n","Loss at epoch 18 is 0.3702886402606964\n","Brier score at epoch 18 is 0.014101375000476837\n","Loss at epoch 19 is 0.30927416682243347\n","Brier score at epoch 19 is 0.012685218751430511\n","Loss at epoch 20 is 0.48195528984069824\n","Brier score at epoch 20 is 0.011588156249523163\n","Loss at epoch 21 is 0.35569000244140625\n","Brier score at epoch 21 is 0.011192593750953675\n","Loss at epoch 22 is 0.2193317413330078\n","Brier score at epoch 22 is 0.010004750000238418\n","Loss at epoch 23 is 0.13387218117713928\n","Brier score at epoch 23 is 0.009724468750953674\n","Loss at epoch 24 is 0.19947463274002075\n","Brier score at epoch 24 is 0.00919990625143051\n","Loss at epoch 25 is 0.3140037953853607\n","Brier score at epoch 25 is 0.008521656250953673\n","Loss at epoch 26 is 0.32252341508865356\n","Brier score at epoch 26 is 0.008089562501907349\n","Loss at epoch 27 is 0.18110409379005432\n","Brier score at epoch 27 is 0.007360093749761582\n","Loss at epoch 28 is 0.15768973529338837\n","Brier score at epoch 28 is 0.0071184687495231625\n","Loss at epoch 29 is 0.2854308485984802\n","Brier score at epoch 29 is 0.006666781251430511\n","Loss at epoch 30 is 0.12692983448505402\n","Brier score at epoch 30 is 0.0063426875001192096\n","Loss at epoch 31 is 0.2742263078689575\n","Brier score at epoch 31 is 0.0057291250002384185\n","Loss at epoch 32 is 0.14566370844841003\n","Brier score at epoch 32 is 0.0058334687501192094\n","Loss at epoch 33 is 0.13046397268772125\n","Brier score at epoch 33 is 0.005923218749761581\n","Loss at epoch 34 is 0.1459927260875702\n","Brier score at epoch 34 is 0.0050440625\n","Loss at epoch 35 is 0.16729985177516937\n","Brier score at epoch 35 is 0.005123531250357628\n","Loss at epoch 36 is 0.11829320341348648\n","Brier score at epoch 36 is 0.004797312500476837\n","Loss at epoch 37 is 0.10258716344833374\n","Brier score at epoch 37 is 0.004601281249523163\n","Loss at epoch 38 is 0.07891394942998886\n","Brier score at epoch 38 is 0.0044330625003576275\n","Loss at epoch 39 is 0.15023985505104065\n","Brier score at epoch 39 is 0.004641343750953674\n","NLL Loss is 0.15023985505104065\n","Brier score is 0.004641343750953674\n","Training time: 2794.6892347335815 seconds\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4Hh9bgg_LohS"},"source":[""],"execution_count":null,"outputs":[]}]}