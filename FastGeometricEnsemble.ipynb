{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"FastGeometricEnsemble.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNr46U8v24fBOoYq3eT/+aw"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"ZJC3cd3M8isX"},"source":["<h1>Loss Surfaces, Mode Connectivity, and Fast Ensembling of DNNs<h1/>\n","\n","Timur Garipov, Pavel Izmailov, Dmitrii Podoprikhin, Dmitry Vetrov, Andrew Gordon Wilson\n"]},{"cell_type":"markdown","metadata":{"id":"2-LgIx5m8xZ0"},"source":["<h2>Classification with Wide ResNet and CIFAR10<h2/>"]},{"cell_type":"code","metadata":{"id":"Q4a78yay8v45","executionInfo":{"status":"ok","timestamp":1610109399867,"user_tz":-120,"elapsed":4170,"user":{"displayName":"Zhiheng Qian","photoUrl":"","userId":"13654940909956400032"}}},"source":["import os\n","import time\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","m = nn.Softplus()"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KLFK2g0h8z3E","executionInfo":{"status":"ok","timestamp":1610109423436,"user_tz":-120,"elapsed":22914,"user":{"displayName":"Zhiheng Qian","photoUrl":"","userId":"13654940909956400032"}},"outputId":"b70b58e2-f6b8-4294-fc33-327a86ba78b4"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9mgKnTXM81DX","executionInfo":{"status":"ok","timestamp":1610109433746,"user_tz":-120,"elapsed":9266,"user":{"displayName":"Zhiheng Qian","photoUrl":"","userId":"13654940909956400032"}},"outputId":"db5687c5-e030-4c44-c297-34831f2e4dce"},"source":["import torchvision\n","import torchvision.transforms as transforms\n","data_dir = '/content/drive/My Drive/AALTO/cs4875-research/data/'\n","transform = transforms.Compose([\n","    transforms.ToTensor(),  # Transform to tensor\n","    transforms.Normalize((0.5,), (0.5,))  # Min-max scaling to [-1, 1]\n","])\n","\n","trainset = torchvision.datasets.CIFAR10(root=data_dir, train=True, download=True, transform=transform)\n","testset = torchvision.datasets.CIFAR10(root=data_dir, train=False, download=True, transform=transform)\n","\n","classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n","\n","trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True)\n","testloader = torch.utils.data.DataLoader(testset, batch_size=5, shuffle=False)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Files already downloaded and verified\n","Files already downloaded and verified\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Rxlaax3m85Mm","executionInfo":{"status":"ok","timestamp":1610109437552,"user_tz":-120,"elapsed":1524,"user":{"displayName":"Zhiheng Qian","photoUrl":"","userId":"13654940909956400032"}}},"source":["class Block(nn.Module):\n","    def __init__(self, in_channels, out_channels, dropout_rate, stride=1):\n","        \"\"\"\n","        Args:\n","          in_channels:  Number of input channels.\n","          out_channels: Number of output channels.\n","          dropout_rate:  Dropout Rate\n","          stride:       Controls the stride.\n","        \"\"\"\n","        super(Block, self).__init__()\n","        self.conv = nn.Sequential(\n","            nn.BatchNorm2d(in_channels),\n","            nn.ReLU(inplace = True),\n","            nn.Conv2d(in_channels, out_channels, kernel_size=3, bias=False, padding = 1),\n","            nn.Dropout(p = dropout_rate),\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(inplace = True),\n","            nn.Conv2d(out_channels, out_channels, kernel_size=3, bias=False, stride = stride, padding = 1)\n","        )\n","        self.skip = nn.Sequential()\n","        if stride != 1 or in_channels != out_channels:\n","            self.skip = nn.Sequential(\n","               nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n","            )\n","\n","    def forward(self, x):\n","        out = self.conv(x)\n","        out += self.skip(x)\n","        return out\n","\n","class GroupOfBlocks(nn.Module):\n","    def __init__(self, in_channels, out_channels, n_blocks, dropout_rate, stride=1):\n","        super(GroupOfBlocks, self).__init__()\n","        strides = [stride] + [1]*(int(n_blocks) - 1)\n","        self.in_channels = in_channels\n","        group = []\n","\n","        for stride in strides:\n","            group.append(Block(self.in_channels, out_channels, dropout_rate, stride))\n","            self.in_channels = out_channels\n","\n","        self.group = nn.Sequential(*group)\n","\n","    def forward(self, x):\n","        return self.group(x)\n","\n","class WideResNet(nn.Module):\n","    def __init__(self, depth, widen_factor, dropout_rate, num_classes=10):\n","        super(WideResNet, self).__init__()\n","        assert ((depth-4)%6 == 0), \"Depth should be 6n+4.\"\n","        n = (depth - 4)/6\n","        k = widen_factor\n","        nStages = [16, 16*k, 32*k, 64*k]\n","\n","        self.conv1 = nn.Conv2d(in_channels=3, out_channels=nStages[0], kernel_size=3, stride=1, padding=1, bias=False)\n","        self.group1 = GroupOfBlocks(nStages[0], nStages[1], n, dropout_rate)\n","        self.group2 = GroupOfBlocks(nStages[1], nStages[2], n, dropout_rate, stride=2)\n","        self.group3 = GroupOfBlocks(nStages[2], nStages[3], n, dropout_rate, stride=2)\n","        self.bn1 = nn.BatchNorm2d(nStages[3])\n","\n","        self.relu = nn.ReLU(inplace=True)\n","        self.fc = nn.Linear(nStages[3], num_classes)\n","        self.nStage3 = nStages[3]\n","\n","        # Initialize weights\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d):\n","                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n","                m.weight.data.normal_(0, np.sqrt(2. / n))\n","            elif isinstance(m, nn.BatchNorm2d):\n","                m.weight.data.fill_(1)\n","                m.bias.data.zero_()\n","\n","    def forward(self, x):\n","        x = self.conv1(x)\n","\n","        x = self.group1(x)\n","        x = self.group2(x)\n","        x = self.group3(x)\n","        x = self.relu(self.bn1(x))\n","        x = F.avg_pool2d(x, 8)\n","        x = x.view(-1, self.nStage3)\n","        return self.fc(x)"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"y1SDbVQs85I_","executionInfo":{"status":"ok","timestamp":1610109440530,"user_tz":-120,"elapsed":1279,"user":{"displayName":"Zhiheng Qian","photoUrl":"","userId":"13654940909956400032"}}},"source":["# code adapted from https://github.com/timgaripov/dnn-mode-connectivity\n","\n","def learning_rate_schedule(base_lr, epoch, total_epochs):\n","    alpha = epoch / total_epochs\n","    if alpha <= 0.5:\n","        factor = 1.0\n","    elif alpha <= 0.9:\n","        factor = 1.0 - (alpha - 0.5) / 0.4 * 0.99\n","    else:\n","        factor = 0.01\n","    return factor * base_lr\n","\n","def adjust_learning_rate(optimizer, lr):\n","    for param_group in optimizer.param_groups:\n","        param_group['lr'] = lr\n","    return lr\n","\n"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":385},"id":"0YdDhP5i5wll","executionInfo":{"status":"error","timestamp":1610109838628,"user_tz":-120,"elapsed":307724,"user":{"displayName":"Zhiheng Qian","photoUrl":"","userId":"13654940909956400032"}},"outputId":"aa2192f5-cc7c-46dd-9c2b-6ff05104c45b"},"source":["device = torch.device('cuda:0')\n","loss_func = nn.CrossEntropyLoss()\n","m = nn.LogSoftmax(dim=1)\n","\n","\n","def compute_brier_score(p, y):\n","  brier_score = torch.mean((y-torch.argmax(p, 1).float())**2)\n","  return brier_score\n","\n","def ensembleFGE(model, optimizer):\n","  running_loss = 0.0\n","  running_brier = 0.0\n","  startEpoch = 1\n","  for epoch in range(startEpoch, numEpochs):\n","    # model.train()\n","    learning_rate = learning_rate_schedule(0.01, epoch, numEpochs)\n","    adjust_learning_rate(optimizer, learning_rate)\n","    brier_score = 0.0\n","    total = 0\n","    for iter, (x, y) in enumerate(trainloader):\n","        x, y = x.to(device), y.to(device)\n","        optimizer.zero_grad()\n","        output = model(x)\n","        batch_brier_score = compute_brier_score(output, y)\n","        brier_score += torch.sum(batch_brier_score, 0).cpu().numpy().item()\n","        loss = loss_func(output, y)\n","        loss.backward()\n","        optimizer.step()\n","        total += y.size(0)\n","    if epoch == (numEpochs-1):\n","      running_loss = loss.item()\n","    print('Loss at epoch {} is {}'.format(epoch, loss.item()))\n","    print('Brier score at epoch {} is {}'.format(epoch, brier_score/total))\n","  return running_loss, brier_score/total\n","\n","\n","numEpochs = 200\n","lr = 0.1\n","training_loss = []\n","training_brier = []\n","t0 = time.time()\n","model = WideResNet(28, 10, 0.5)\n","model.to(device)\n","optimizer = torch.optim.SGD(\n","    filter(lambda param: param.requires_grad, model.parameters()),\n","    lr=lr,\n","    momentum=0.9,\n","    weight_decay=5e-4\n",")\n","loss, brier = ensembleFGE(model, optimizer)\n","print('NLL Loss is {}'.format(np.mean(loss)))\n","print('Brier score is {}'.format(np.mean(brier)))\n","print('Training time: {} seconds'.format(time.time() - t0))\n"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Loss at epoch 1 is 1.4771322011947632\n","Brier score at epoch 1 is 0.10701743749618531\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-89d9f7747b8f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5e-4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m )\n\u001b[0;32m---> 50\u001b[0;31m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbrier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensembleFGE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'NLL Loss is {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Brier score is {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbrier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-9-89d9f7747b8f>\u001b[0m in \u001b[0;36mensembleFGE\u001b[0;34m(model, optimizer)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mbatch_brier_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_brier_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mbrier_score\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_brier_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"QR4nQm6k85F2"},"source":["torch.save(model.state_dict(), '/content/drive/My Drive/AALTO/cs4875-research/archive/fge_ensemble.pth')\n","print('Model saved to %s.' % ('fge_ensemble.pth'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dqwdHg4P84-S"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KBRLMIN78452"},"source":[""],"execution_count":null,"outputs":[]}]}